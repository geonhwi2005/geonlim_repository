<<<<<<< HEAD
# Evaluate_model.py

import tensorflow as tf
from tensorflow import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from dataset.dataset_loader import DataLoader
from train import CTCLoss # Import the custom loss function for loading

# --- Configuration ---
MODEL_PATH = 'your model path'
CSV_PATH = 'your csv path'
BATCH_SIZE = 32
IMAGE_WIDTH = 1024
IMAGE_HEIGHT = 128

def decode_batch_predictions(pred, num_to_char):
    """Decodes raw model predictions into human-readable text."""
    input_len = np.ones(pred.shape[0]) * pred.shape[1]
    # Use CTC decoder
    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][
        :, :num_to_char.vocabulary_size()
    ]
    # Convert numerical indices back to characters
    output_text = []
    for res in results:
        res_text = tf.strings.reduce_join(num_to_char(res)).numpy().decode("utf-8")
        output_text.append(res_text)
    return output_text

def evaluate():
    # 1. Prepare the data
    df = pd.read_csv(CSV_PATH)
    data_loader = DataLoader(df, BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT)
    _, _, test_ds = data_loader.split_data() # Use only the test dataset

    # 2. Load the trained model
    # Load with custom objects dictionary
    custom_objects = {"CTCLoss": CTCLoss}
    model = keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)
    print("âœ… Model loaded successfully!")

    # 3. Evaluate the model on the test set
    print("ğŸ“Š Evaluating on the test dataset...")
    results = model.evaluate(test_ds)
    print(f"Test Loss: {results}")

    # 4. Visualize predictions
    for batch in test_ds.take(1):
        batch_images = batch["image"]
        batch_labels = batch["label"]

        preds = model.predict(batch_images)
        pred_texts = decode_batch_predictions(preds, data_loader.num_to_char)

        orig_texts = []
        for label in batch_labels:
            label_text = tf.strings.reduce_join(data_loader.num_to_char(label)).numpy().decode("utf-8")
            orig_texts.append(label_text.replace('[UNK]', '').strip())

        _, axes = plt.subplots(4, 4, figsize=(15, 8))

        for i in range(min(16, len(pred_texts))):
            img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)
            img = img.T
            
            title = f"Pred: {pred_texts[i]}\nTrue: {orig_texts[i]}"
            
            ax = axes[i // 4, i % 4]
            ax.imshow(img, cmap="gray")
            ax.set_title(title, fontsize=9)
            ax.axis("off")

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    evaluate()
=======
# Evaluation.py (ìˆ˜ì • ë²„ì „)
import numpy as np
import cv2
import editdistance
import tensorflow as tf
from tensorflow.keras.models import load_model
from dataset.dataset_loader import load_csv, DataGenerator, num_to_label
from models.CRNN_Model import ctc_lambda_func  # Custom loss import

def ctc_decode_predictions(y_pred, input_length):
    """TensorFlow 2.x í˜¸í™˜ CTC ë””ì½”ë”©"""
    # Tensorë¥¼ numpyë¡œ ë³€í™˜
    if isinstance(input_length, tf.Tensor):
        input_length = input_length.numpy()
    
    # CTC ë””ì½”ë”© (TensorFlow 2.x ë°©ì‹)
    decoded_dense, _ = tf.nn.ctc_greedy_decoder(
        inputs=tf.transpose(y_pred, [1, 0, 2]),  # (time, batch, classes)
        sequence_length=input_length.flatten()
    )
    
    # SparseTensorë¥¼ denseë¡œ ë³€í™˜
    decoded_dense = tf.sparse.to_dense(decoded_dense[0], default_value=-1)
    return decoded_dense.numpy()

def evaluate_model(model_path, test_csv, test_dir):
    """ëª¨ë¸ í‰ê°€ ë©”ì¸ í•¨ìˆ˜ (ìˆ˜ì • ë²„ì „)"""
    
    # 1. ëª¨ë¸ ë¡œë“œ (Custom objects í¬í•¨)
    print("ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        # Base model ë¡œë“œ ì‹œë„
        model = load_model(model_path)
    except:
        # Custom CTC lossê°€ í¬í•¨ëœ ê²½ìš°
        model = load_model(model_path, custom_objects={'ctc_lambda_func': ctc_lambda_func})
    
    print(f"ëª¨ë¸ ì…ë ¥ shape: {model.input_shape}")
    print(f"ëª¨ë¸ ì¶œë ¥ shape: {model.output_shape}")
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    print("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
    test_df = load_csv(test_csv)
    test_gen = DataGenerator(
        test_df,
        test_dir,
        batch_size=32,
        target_h=64,
        max_w=256
    )
    
    # 3. ì˜ˆì¸¡ ìˆ˜í–‰
    print("ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    y_true_labels = []
    y_pred_labels = []
    
    for i in range(len(test_gen)):
        batch_data, _ = test_gen[i]
        batch_images = batch_data[0]
        batch_true_labels = batch_data[1]
        batch_input_lengths = batch_data[2]
        
        # ëª¨ë¸ ì˜ˆì¸¡ (base modelë§Œ ì‚¬ìš©)
        predictions = model.predict(batch_images, verbose=0)
        
        # CTC ë””ì½”ë”© (ìˆ˜ì •ëœ ë°©ì‹)
        decoded_preds = ctc_decode_predictions(predictions, batch_input_lengths)
        
        # ê²°ê³¼ ë³€í™˜
        for j in range(len(batch_true_labels)):
            # True label ë³€í™˜
            true_label = batch_true_labels[j]
            true_text = num_to_label(true_label[true_label >= 0])
            
            # Predicted label ë³€í™˜
            if j < len(decoded_preds):
                pred_indices = decoded_preds[j]
                pred_text = num_to_label(pred_indices[pred_indices >= 0])
            else:
                pred_text = ""
            
            y_true_labels.append(true_text)
            y_pred_labels.append(pred_text)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (ì²˜ìŒ 10ê°œë§Œ)
            if len(y_true_labels) <= 10:
                print(f"Sample {len(y_true_labels)}: True='{true_text}', Pred='{pred_text}'")
    
    # 4. í‰ê°€ ì§€í‘œ ê³„ì‚°
    print("\n=== í‰ê°€ ê²°ê³¼ ===")
    
    # ì •í™•ë„
    correct = sum(1 for true, pred in zip(y_true_labels, y_pred_labels) if true == pred)
    accuracy = correct / len(y_true_labels)
    print(f"ì •í™•ë„ (Exact Match): {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„
    total_distance = 0
    total_length = 0
    for true_label, pred_label in zip(y_true_labels, y_pred_labels):
        distance = editdistance.eval(true_label, pred_label)
        total_distance += distance
        total_length += max(len(true_label), len(pred_label))
    
    similarity = 1 - (total_distance / total_length) if total_length > 0 else 0
    print(f"í¸ì§‘ ê±°ë¦¬ ìœ ì‚¬ë„: {similarity:.4f} ({similarity*100:.2f}%)")
    
    print(f"\nì´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(y_true_labels)}")
    return accuracy, similarity

if __name__ == '__main__':
    # í‰ê°€ ì‹¤í–‰ - base model ê²½ë¡œë¡œ ìˆ˜ì •
    model_path = 'final_densenet_crnn_rtx3070.h5'  # base model ì‚¬ìš©
    test_csv = 'dataset/handwriting-recognition/written_name_test_v2.csv'
    test_dir = 'dataset/handwriting-recognition/test_v2/test'
    
    evaluate_model(model_path, test_csv, test_dir)
>>>>>>> 3dc3c155bd117d90c00fde6e54a01068df22ea2a
